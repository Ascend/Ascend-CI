name: llama.cpp

defaults:
  run:
    shell: bash -el {0}
on:
  workflow_dispatch:
  pull_request:
    paths:
      - '.github/workflows/llamacpp.yaml'
      - 'requirements/**'

  push:
    paths:
        - '.github/workflows/llamacpp.yaml'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  issues: write

jobs:
  unit-tests:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        cann: ['python3.10-cann8.0.rc3.beta1']
        build: ['Release']

    container:
      image: ascendai/cann:openeuler-${{ matrix.cann }}

    steps:
    - uses: actions/checkout@v4

    - name: Install llamacpp
      uses: nick-fields/retry@v3
      with:
        timeout_minutes: 30
        max_attempts: 3
        retry_on: error
        command: |
          yum update -y
          yum install git cmake gcc gcc-c++ make -y
          
          git clone https://github.com/ggerganov/llama.cpp.git

    - name: Build
      run: |
          cat /root/.bashrc
          cat /usr/local/Ascend/ascend-toolkit/set_env.sh
          export LIBRARY_PATH=${ASCEND_TOOLKIT_HOME}/lib64:${LIBRARY_PATH}
          echo "-----------111111111-----------------"
          echo $LIBRARY_PATH
          echo "----------111111111111------------------"
          cd llama.cpp
          mkdir build
          cd build
          cmake .. -DCMAKE_BUILD_TYPE=${{ matrix.build }} -DGGML_CANN=on && make -j32
          
  ubuntu-unit-tests:
    runs-on: ubuntu-latest

    container:
      image: ascendai/cann

    steps:
    - uses: actions/checkout@v4

    - name: Install llamacpp
      uses: nick-fields/retry@v3
      with:
        timeout_minutes: 30
        max_attempts: 3
        retry_on: error
        command: |
          apt-get update -y
          apt-get install git cmake build-essential make -y
          
          git clone https://github.com/ggerganov/llama.cpp.git

    - name: Build
      run: |
          cat /root/.bashrc
          cat /usr/local/Ascend/ascend-toolkit/set_env.sh
          export LIBRARY_PATH=${ASCEND_TOOLKIT_HOME}/lib64:${LIBRARY_PATH}
          echo "-----------111111111-----------------"
          echo $LIBRARY_PATH
          echo "----------111111111111------------------"
          cd llama.cpp
          cmake -B build -DCMAKE_BUILD_TYPE=release -DGGML_CANN=on
          cmake --build build -j $(nproc)



    

    
    
