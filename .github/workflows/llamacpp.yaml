name: llama.cpp

defaults:
  run:
    shell: bash -ieo pipefail {0}
on:
  workflow_dispatch:
  pull_request:
    paths:
      - '.github/workflows/llamacpp.yaml'
      - 'requirements/**'

  push:
    paths:
        - '.github/workflows/llamacpp.yaml'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  issues: write

jobs:
  unit-tests:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        cann: ['8.0.rc2.beta1']
        build: ['Release']

    container:
      image: ascendai/cann:${{ matrix.build }}-910b-openeuler22.03-py3.9

    steps:
    - uses: actions/checkout@v4

    - name: Install llamacpp
      uses: nick-fields/retry@v3
      with:
        timeout_minutes: 30
        max_attempts: 3
        retry_on: error
        command: |
          yum update -y
          yum install git cmake gcc gcc-c++ make -y

          git clone https://github.com/ggerganov/llama.cpp.git

    - name: Build
      run: |
          cd llama.cpp
          mkdir build
          cd build
          cmake .. -DCMAKE_BUILD_TYPE=${{ matrix.build }} -DWITH_CANN=on
          cmake --build . -j $(nproc)



    

    
    
