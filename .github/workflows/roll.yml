name: Roll

on:
  workflow_dispatch:
    inputs:
      runner:
        required: true
        type: choice
        options:
          - linux-arm64-npu-1
          - linux-arm64-npu-2
          - linux-arm64-npu-4

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  roll:
    runs-on: ${{ inputs.runner }}
    steps:
      - name: Show NPU info
        run: |
          npu-smi info

      - name: Config mirrors
        run: |
          sed -i 's|ports.ubuntu.com|mirrors.tuna.tsinghua.edu.cn|g' /etc/apt/sources.list
          pip config set global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple

      - name: Install system dependencies
        run: |
          apt-get update
          apt-get install -y \
            git gcc g++ make cmake ninja-build curl \
            libgl1 libglib2.0-0 libsndfile1 libcurl4-openssl-dev unzip

      - name: Checkout
        uses: actions/checkout@v4

      - name: Checkout ROLL
        uses: actions/checkout@v4
        with:
          repository: alibaba/ROLL
          path: ROLL

      - name: Install dependencies
        run: |
          pip install torch==2.7.1 torch==2.7.1rc1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
          pip install vllm==0.10.0
          pip install "numpy==1.26.4" "optree>=0.13.0" "spacy==3.7.5" "weasel==0.4.1"  transformers==4.52.4\
            transformer-engine[pytorch]==2.2.0 megatron-core==0.11.0 deepspeed==0.16.4 \
            --trusted-host mirrors.aliyun.com --index-url https://mirrors.aliyun.com/pypi/simple/
          pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.2.post1/flash_attn-2.7.2.post1+cu12torch2.6cxx11abiFALSE-cp310-cp310-linux_x86_64.whl

      - name: Install ROLL
        working-directory: ROLL
        run: |
          pip install -e .


          